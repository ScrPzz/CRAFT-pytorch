{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeae5075-f73a-45ee-b358-f111f6789b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/clovaai/deep-text-recognition-benchmark#download-lmdb-dataset-for-traininig-and-evaluation-from-here\n",
    "# https://github.com/clovaai/CRAFT-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a0add472-ddfa-4e33-8168-e03ed165ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import urllib.parse\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import types\n",
    "from collections import namedtuple\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39595f4b-d404-4b55-a182-6e635129c08e",
   "metadata": {},
   "source": [
    "### paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "087725e4-f70c-4b45-8308-fabd25a4ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.abspath(os.path.join(root, name)))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8ba164f2-270a-4e4b-ba7e-013532c2d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_paths=list_files('./test_images/post_imgs/TEST/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2159a549-a2fd-40af-8601-eccfcfdb04a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/Ca-GHMas63y.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CezOjxXOalw_1.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/Cb8fMmqFr6u.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CcOnQYnOcmB.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CezOjxXOalw_4.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/Cb_FuDsFwyJ_0.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CY9MkcNOuHg.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CH_JQugBNjc_2.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/Cb_FuDsFwyJ_2.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CcqKL8kON2G_0.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/craft_mlt_25k.pth',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/Cb_FuDsFwyJ_3.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/Cb_FuDsFwyJ_1.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CH_JQugBNjc_1.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CcqKL8kON2G/CcqKL8kON2G_3.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CcqKL8kON2G/CcqKL8kON2G_1.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CcqKL8kON2G/CcqKL8kON2G_4.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CcqKL8kON2G/CcqKL8kON2G_2.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CZMvd-LuNFJ/CZMvd-LuNFJ_2.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CZMvd-LuNFJ/CZMvd-LuNFJ_3.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CZMvd-LuNFJ/CZMvd-LuNFJ_0.jpg',\n",
       " '/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CZMvd-LuNFJ/CZMvd-LuNFJ_1.jpg']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d5989577-bb47-4502-832b-cefb422a8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./output')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b8f864f4-698f-4548-ad24-48e2f7953a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in imgs_paths:\n",
    "    shutil.copyfile(p, f\"./output/{p.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b9d42-795d-46d4-8a22-65bf6bbefba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e91d7a64-b25b-4a49-874d-ddb132dbab87",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/home/atogni/Desktop/ocr_gradient/test_images/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "1   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "2   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "3   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "4   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "5   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "6   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "7   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "8   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "9   /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "10  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "11  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "12  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "13  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "14  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "15  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "16  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "17  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "18  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "19  /home/atogni/Desktop/ocr_gradient/test_images/...\n",
       "20  /home/atogni/Desktop/ocr_gradient/test_images/..."
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(imgs_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e37e66b6-98f7-4bc4-8e06-39df295531ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_path='./output/'\n",
    "bboxes_path=urllib.parse.urljoin(b_path,'bboxes_infos.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03419e-efa0-40e1-b10c-1556b0dd3b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urljoin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [193]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43murljoin\u001b[49m(b_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbboxes_infos.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urljoin' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e3f32be3-6c41-4d93-bb08-d8577ada65ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/bboxes_infos.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [192]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbboxes_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     boxes\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/bboxes_infos.json'"
     ]
    }
   ],
   "source": [
    "with open(bboxes_path) as f:\n",
    "    boxes=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "eb742540-9bb3-446b-a5d5-6fc931cf0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(urllib.parse.urljoin(b_path, 'res_CH_JQugBNjc_2.jpg'))\n",
    "width, height = im.size\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7348141-eb26-4f67-a7f9-eabdbb26817b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def show_cv_to_pil(cv_img):\n",
    "        \"Auxiliary function to fix opencv.show() not working on linux\"\n",
    "        cv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        im_pil = Image.fromarray(cv_img)\n",
    "        im_pil.show()\n",
    "\n",
    "\n",
    "class BoxesEngine():\n",
    "    \n",
    "    def extract_area_of_4boxes_list(self, list_bboxes):\n",
    "        \"Extract area of a list of boxes in 4 vertex format\"\n",
    "        a=0.0\n",
    "        for box in list_bboxes:\n",
    "            dx=round(max(box[0][0], box[1][0]) - min(box[0][0], box[1][0]), 2)\n",
    "            dy=round(max(box[0][1], box[3][1]) - min(box[0][1], box[3][1]), 2)\n",
    "            a+=dx*dy\n",
    "        return round(a, 0)\n",
    "    \n",
    "    def extract_area_of_tl_br_box_list(self,tl_br_tup_lst):\n",
    "        \"Calculate area of a tl_dr box list\"\n",
    "        a=0.0\n",
    "        for tl_br_tup in tl_br_tup_lst:\n",
    "            dx=round(max(tl_br_tup[0][0], tl_br_tup[1][0]) - min(tl_br_tup[0][0], tl_br_tup[1][0]), 0)\n",
    "            dy=round(max(tl_br_tup[0][1], tl_br_tup[1][1]) - min(tl_br_tup[0][1], tl_br_tup[1][1]), 0)\n",
    "            a+= int(dx*dy)\n",
    "        return a\n",
    "\n",
    "    def _4bbox_to_tl_br(self,box_vertices):\n",
    "        \"\"\"Transform 4-vertex box to named tuple:\n",
    "        Box = namedtuple(\"Box\", \"top_left bottom_right dx dy\")\"\"\"\n",
    "\n",
    "        tl=[min([v[0] for v in box_vertices]), min([v[1] for v in box_vertices])]\n",
    "        br=[max([v[0] for v in box_vertices]), max([v[1] for v in box_vertices])]\n",
    "        dx=round(max(box_vertices[0][0], box_vertices[1][0]) - min(box_vertices[0][0], box_vertices[1][0]), 2)\n",
    "        dy=round(max(box_vertices[0][1], box_vertices[3][1]) - min(box_vertices[0][1], box_vertices[3][1]), 2)\n",
    "\n",
    "        return Box(tl, br, dx, dy)\n",
    "\n",
    "\n",
    "    def tl_br_list_to_centers(self,tl_dr_Idx_Box, round_to=int):\n",
    "        \"Extract boxes centers from list of Idx_Box named tuple\"\n",
    "        centers=[]\n",
    "        for box in tl_dr_Idx_Box:\n",
    "            if round_to >0:\n",
    "                centers.append((box.id, [round(box.top_left[0] + 0.5*(box.dx), round_to), round(box.top_left[1] + 0.5*(box.dy) , round_to) ]))\n",
    "            else:\n",
    "                centers.append((box.id, [int(box.top_left[0] + 0.5*(box.dx)), int(box.top_left[1] + 0.5*(box.dy)) ]))\n",
    "        return centers\n",
    "\n",
    "\n",
    "    def create_big_box_from_ids(self,ids, boxes_data):\n",
    "        \"Merge boxes from id list into a single box\"\n",
    "        to_bound=[]\n",
    "        for box in boxes_data:\n",
    "            if getattr(box, 'id') in ids: to_bound.append(box) \n",
    "        to_bound.sort(key=lambda a: a.top_left[0])\n",
    "        TLx=to_bound[0].top_left[0]\n",
    "        to_bound.sort(key=lambda a: a.top_left[1])\n",
    "        TLy=to_bound[0].top_left[1]\n",
    "\n",
    "        to_bound.sort(key=lambda a: a.bottom_right[0])\n",
    "        BRx=to_bound[-1].bottom_right[0]\n",
    "        to_bound.sort(key=lambda a: a.bottom_right[1])\n",
    "        BRy=to_bound[-1].bottom_right[1]\n",
    "\n",
    "        return [(int(TLx), int(TLy)), (int(BRx), int(BRy))]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af3c70a-8e17-45f1-981a-1589de2554f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_engine=BoxesEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659845fc-11e6-42ea-8d5b-f6348b683bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57153.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes_engine.extract_area_of_4boxes_list(list_bboxes=boxes['CH_JQugBNjc_2.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef53b710-a6ac-481e-8381-9d5fc69544cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pct area covered by text boxes: 15.82%'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Pct area covered by text boxes: {round((boxes_engine.extract_area_of_4boxes_list(boxes['CH_JQugBNjc_2.jpg']) / (width*height))*100, 2)}%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be6ec3d-5e98-4a7e-afeb-08ae414941b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Box = namedtuple(\"Box\", \"top_left bottom_right dx dy\")\n",
    "Idx_Box=namedtuple(\"Idx_Box\", \"id top_left bottom_right dx dy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7d877d9-f9f2-4fa3-b7b2-bfa6c48b16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tldr_boxes={}\n",
    "n=0\n",
    "for k, v in boxes.items():\n",
    "    tldr_boxes[k]=[boxes_engine._4bbox_to_tl_br(box_vertices=box) for box in v]\n",
    "    \n",
    "for k, v in tldr_boxes.items():\n",
    "    for i in range(len(v)):\n",
    "        v[i]=Idx_Box(i, *v[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1cd38f9-585a-427a-a0ae-fb4657566179",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_list=tldr_boxes['CH_JQugBNjc_2.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d26accfc-70ae-4ec5-9d4e-2586edeafd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Idx_Box(id=0, top_left=[271.4495544433594, 61.836456298828125], bottom_right=[543.1077270507812, 100.0404281616211], dx=270.89, dy=31.68),\n",
       " Idx_Box(id=1, top_left=[272.0000305175781, 98.66665649414062], bottom_right=[572.0, 130.66665649414062], dx=300.0, dy=32.0),\n",
       " Idx_Box(id=2, top_left=[41.33333206176758, 230.6666717529297], bottom_right=[250.6666717529297, 258.6666564941406], dx=209.33, dy=28.0),\n",
       " Idx_Box(id=3, top_left=[40.0, 268.0], bottom_right=[166.6666717529297, 296.0], dx=126.67, dy=28.0),\n",
       " Idx_Box(id=4, top_left=[37.33333206176758, 304.0], bottom_right=[202.6666717529297, 336.0], dx=165.33, dy=32.0),\n",
       " Idx_Box(id=5, top_left=[37.26239776611328, 331.88360595703125], bottom_right=[181.06959533691406, 371.5979919433594], dx=141.64, dy=29.22),\n",
       " Idx_Box(id=6, top_left=[347.3746643066406, 402.5814208984375], bottom_right=[563.505126953125, 440.4438781738281], dx=215.1, dy=30.6),\n",
       " Idx_Box(id=7, top_left=[346.6666564941406, 441.3333435058594], bottom_right=[508.0, 469.3333435058594], dx=161.33, dy=28.0),\n",
       " Idx_Box(id=8, top_left=[348.0, 474.6666564941406], bottom_right=[536.0, 502.6666564941406], dx=188.0, dy=28.0),\n",
       " Idx_Box(id=9, top_left=[348.0, 512.0], bottom_right=[482.6666564941406, 540.0], dx=134.67, dy=28.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e715ce1-e7be-46ca-8882-3fbeb7616285",
   "metadata": {},
   "source": [
    "### Solution: MeanShift clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50e49b4e-1480-42f7-9cae-8834d965e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_box=namedtuple(\"clustered_box\", \"id top_left bottom_right dx dy cluster_id\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91db6d47-f007-45f2-895f-da7c5e826af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fde1311f-de21-4c75-8fab-d4cc996685be",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers=boxes_engine.tl_br_list_to_centers(b_list, round_to=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5352efe-152d-4c86-bf0c-9fe1aefefc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([c[1] for c in centers])\n",
    "clst = MeanShift(bandwidth=None).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97ceeea1-3614-491a-87ec-61075a433992",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id_to_box_id=list(zip(clst.labels_, [c[0] for c in centers] ))\n",
    "clustered_boxes = defaultdict(list)\n",
    "for x in cluster_id_to_box_id:\n",
    "    clustered_boxes[x[0]].append(x[1])\n",
    "clustered_boxes_ids=dict(clustered_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58993c9b-ffa7-49d6-b230-602349d7751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_br_text_boxes=[]\n",
    "for k, v in clustered_boxes_ids.items():\n",
    "    tl_br_text_boxes.append(boxes_engine.create_big_box_from_ids(v, tldr_boxes['CH_JQugBNjc_2.jpg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af653425-ec82-403c-8762-9497bd98675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing results\n",
    "orig_img=cv2.imread(urllib.parse.urljoin(b_path, 'res_CH_JQugBNjc_2.jpg'))\n",
    "big_boxes_img=orig_img.copy()\n",
    "for r in tl_br_text_boxes:\n",
    "    cv2.rectangle(big_boxes_img, r[0], r[1], (255, 0, 0), 2)\n",
    "show_cv_to_pil(big_boxes_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3856903-59c1-4fa0-a4bd-345d98f5ded6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(271, 61), (572, 130)], [(37, 230), (250, 371)], [(346, 402), (563, 540)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_br_text_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d90f7b8-ea81-4880-b139-5b042e0c8384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[enhanced] Pct area covered by text boxes: 22.43%'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"[enhanced] Pct area covered by text boxes: {boxes_engine.extract_area_of_tl_br_box_list(tl_br_text_boxes)/(600**2)*100}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1045f39c-2674-44c0-bb97-f8964ebe6e3e",
   "metadata": {},
   "source": [
    "### OCR pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ed37e99-44d8-4ae2-81e3-a506a959d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Understand if there's highlighted text: bold, full-capslock, higher fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd676039-0a3c-4dea-9d62-9e3044cba0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big boxes segmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c1279e0-c5d4-4652-b789-485d27710d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3a058ff2-183a-40ab-824f-eb73c6e23128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OcrEngine():\n",
    "    \n",
    "    def _preprocess(self,text_box):\n",
    "        gray = cv2.cvtColor(text_box, cv2.COLOR_BGR2GRAY)\n",
    "        text_box_gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        return cv2.medianBlur(gray, 3)\n",
    "\n",
    "    def reconstruct_text_from_pieces(self, text_boxes, original_image, tolerance=int):\n",
    "        full_text=''\n",
    "        for b_ in text_boxes:\n",
    "            text_box=original_image[b_[0][1]-tolerance: b_[1][1]+tolerance, b_[0][0]-tolerance: b_[1][0]+tolerance]\n",
    "            # TODO save text boxes to disk?\n",
    "            # filename = \"{}.png\".format(os.getpid())\n",
    "            # cv2.imwrite(filename, gray)\n",
    "            pr_text_box=self._preprocess(text_box)\n",
    "            text = pytesseract.image_to_string(pr_text_box)\n",
    "            full_text+=(''.join(text.replace('\\n', ' ').splitlines()))\n",
    "        return ' '.join(full_text.split())\n",
    "\n",
    "    def extract_uppers(self, T):\n",
    "        \"Extract list of upper case words from a string of text\"\n",
    "        uppers=[]\n",
    "        for word in T.split(' '):\n",
    "            if word.isupper():\n",
    "                uppers.append(word)\n",
    "            else:\n",
    "                continue\n",
    "        return uppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3abb7728-632e-4f4c-b5ad-0af030deae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_image=cv2.imread('/home/atogni/Desktop/ocr_gradient/test_images/post_imgs/TEST/CH_JQugBNjc_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "71bcf9b0-05dc-4066-abac-30a94a4af197",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_engine=OcrEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a893f53c-c96e-421b-839b-3137b5e27128",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_=tl_br_text_boxes[1]\n",
    "tolerance=5\n",
    "text_box=starting_image[b_[0][1]-tolerance: b_[1][1]+tolerance, b_[0][0]-tolerance: b_[1][0]+tolerance]\n",
    "show_cv_to_pil(text_box)\n",
    "gray_text_box=ocr_engine._preprocess(text_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e9091c22-45c6-4d98-8566-e226c91ff931",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cv_to_pil(gray_text_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "47a6d6bd-a4c9-4999-bc55-a651aad39529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFFORDABLE\n",
      "ENERGY\n",
      "\n",
      "to a growing\n",
      "population 4\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(gray_text_box)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ea14c53f-06e5-4873-8e6d-0c8514a25915",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=ocr_engine.reconstruct_text_from_pieces(text_boxes=tl_br_text_boxes,original_image=starting_image , tolerance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8824cedb-1bac-4b49-91e6-fb677f017403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dual challenge is finding ways to provide AFFORDABLE ENERGY to a growing population He while addressing THE RISKS OF CLIMATE CHANGE'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82812806-abe7-4ff2-bb65-14b7945cb70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFFORDABLE', 'ENERGY', 'THE', 'RISKS', 'OF', 'CLIMATE', 'CHANGE']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_engine.extract_uppers(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4bbcb-7a9a-4ed9-ba0a-4203c03d5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text on the biggest box ~ most emphasized (?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b79784-752d-4e0c-a7fb-330c0e97b57d",
   "metadata": {},
   "source": [
    "### Entities extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2342ee8-1c45-43b3-ad1c-08970c259072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install -U spacy\n",
    "# ! python3 -m spacy download en_core_web_sm\n",
    "# ! pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1a885444-4f78-43f9-9897-59b67d43253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ada3df99-5565-4c63-a87f-9e7d55a04e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d=nlp(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1f847965-0e61-4c62-91d7-e5a3f08855de",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (392350262.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [147]\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "nouns=[]\n",
    "for token in d:\n",
    "    features.append({'token' : token.text, 'pos' : token.pos_})\n",
    "    if token.pos_=='NOUN':\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c527a16f-e1a7-4f32-a2cf-fcf95396cd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dual challenge\n",
      "ways\n",
      "AFFORDABLE ENERGY\n",
      "a growing population\n",
      "THE RISKS\n",
      "CLIMATE CHANGE\n"
     ]
    }
   ],
   "source": [
    "for token in d.noun_chunks:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8600ae0d-0c67-4193-a75b-a4a0201bab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /home/atogni/anaconda3/envs/gradient_ocr/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/atogni/anaconda3/envs/gradient_ocr/lib/python3.10/site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/atogni/anaconda3/envs/gradient_ocr/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/atogni/anaconda3/envs/gradient_ocr/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.4.3\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dab3255f-f736-4aab-885d-e82d2bfee1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "31358ea7-5965-4482-b444-8d631dc22447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"A\":[1,0,1,2,1],\"B\":[2,2,1,0,1],\"C\":[1,1,1,2,1],\"D\":[2,1,2,1,1]})\n",
    "df2 = pd.DataFrame({\"A\":[1],\"B\":[2],\"D\":[4]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c8424682-529f-4e39-b097-2b17c4349237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_cols=df1.columns\n",
    "df2_cols=df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699c645-0969-4ab5-bca3-52eccf5404cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df1_cols) > len(df2_cols):\n",
    "    for c in df1_cols:\n",
    "        if c in df1_cols & c in df2_cols:\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
